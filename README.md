# AI Prophecy Studies
Eunhae Lee (MIT Media Lab), Pat Pataranutaporn (MIT Media Lab), Judith Amores (Microsoft Research), and Pattie Maes (MIT Media Lab)

## Corresponding Authors
Eunhae Lee (eunhae@mit.edu) & Pat Pataranutaporn (patpat@media.mit.edu)

This is a repository for the following studies:

## Study 1: AI as a New Astrology? Believing in AI Predictions about Personal Behavior Correlates with Belief in Astrology and Paranormal Experiences
### Abstract

This study investigates psychological factors influencing belief in AI predictions about personal behavior, comparing it to belief in astrology and personality-based predictions. Through an experiment with 238 participants, we examined how cognitive style, paranormal beliefs, AI attitudes, personality traits, and other factors affect perceived validity, reliability, usefulness, and personalization of predictions from different sources. Our findings reveal that belief in AI predictions is positively correlated with belief in predictions based on astrology and personality psychology. Notably, paranormal beliefs significantly increased perceived validity of AI predictions by 0.32 points (p=0.001) on a 7-point scale, while positive AI attitudes enhanced belief in AI predictions, especially perceived reliability (0.27 point increase, p<0.001). Conscientiousness was negatively correlated with belief in predictions across all sources (-0.20 points, p=0.032), and interest in the prediction topic increased perceived validity across sources (0.30 points, p=0.001). Surprisingly, cognitive style did not significantly influence belief in predictions. These results highlight the "rational superstition" phenomenon in AI, where belief is driven more by mental heuristics and intuition than critical evaluation. We discuss implications for designing AI systems and communication strategies that foster appropriate trust and skepticism. This research contributes to our understanding of human-AI interaction psychology and the broader societal narratives around AI capabilities.

## Study 2: Personal Validation Bias in LLM Use: Positive AI Responses Boost Perceived Validity, Personalization, Reliability, and Usefulness of False Predictions
### Abstract
The rapid advancement and widespread adoption of Large Language Models (LLMs) have ushered in a new era of human-AI interaction, profoundly impacting various domains from education to business decision-making. As these sophisticated AI systems become increasingly integrated into our daily lives, it is crucial to understand the psychological dynamics at play in human-AI interactions. This paper investigates the phenomenon of "Personal Validation Bias" in the context of LLM use, exploring how positive AI responses can significantly influence users' perceptions of the validity, personalization, reliability, and usefulness of predictions, even when those predictions are demonstrably false. Our study (N=238) reveals that positive AI-generated predictions are perceived as significantly more valid (36\% increase), personalized (42\% increase), reliable (27\% increase), and useful (22\% increase) compared to negative predictions. These findings underscore the substantial impact of prediction valence on user perceptions, with implications for the design and deployment of AI systems across various applications.


## Repository Structure

```
├── Data/
│   ├── Raw/
│   ├── Processed/
│   └── Code/
├── Prototype/
│   ├── Survey/
│   ├── Pre-Scripted_Chatbot/
│   └── Generative_Chatbot/
└── Supplementary/
    ├── Survey/
    └── Video/
```


## Repository Contents

### Data

- **Raw**: Original, unprocessed, and de-identified data collected during the study.
- **Processed**: Cleaned and formatted data used for analysis.
- **Code**: Scripts and notebooks used for data analysis and visualization.

### Prototype

- **Survey**: Materials for the survey-based condition.
- **Static Chatbot**: Implementation of the pre-scripted chatbot.
- **Generative Chatbot**: Implementation of the LLM-based generative chatbot.

### Supplementary
- **Survey**: Survey materials and questionnaires used in the study.
- **Video**: Crime-related video (2:30) from the Sayford Supermarket robbery on April 6, 2019, which was used in the experiment. Original video (4:17): https://www.youtube.com/watch?v=KEITMPG321Y&ab_channel=PennLive.com 

## Usage

[Provide instructions on how to use the code and data in this repository]

## Citation

[Provide the citation for the paper once published]

## License

[Specify the license under which this research and its materials are released]

## Acknowledgements

[Include any acknowledgements, funding sources, or other credits]
